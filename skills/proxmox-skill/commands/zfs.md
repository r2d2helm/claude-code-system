# /pve-zfs - Administration ZFS

## Description
Administration complÃ¨te ZFS sur Proxmox VE : pools, datasets, snapshots,
rÃ©plication, et RAIDZ expansion (ZFS 2.3+ / PVE 9+).

## Syntaxe
```
/pve-zfs <action> [pool/dataset] [options]
```

## Actions Disponibles

| Action | Syntaxe | Description |
|--------|---------|-------------|
| `status` | `/pve-zfs status [pool]` | Ã‰tat des pools ZFS |
| `create` | `/pve-zfs create <pool>` | CrÃ©er pool |
| `destroy` | `/pve-zfs destroy <pool>` | Supprimer pool |
| `expand` | `/pve-zfs expand <pool>` | RAIDZ expansion (PVE 9+) |
| `scrub` | `/pve-zfs scrub <pool>` | Lancer scrub |
| `snapshot` | `/pve-zfs snapshot` | GÃ©rer snapshots |
| `replicate` | `/pve-zfs replicate` | RÃ©plication ZFS |
| `send` | `/pve-zfs send` | Envoyer snapshot |
| `receive` | `/pve-zfs receive` | Recevoir snapshot |
| `properties` | `/pve-zfs properties <ds>` | PropriÃ©tÃ©s dataset |

## Affichage Status

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ—„ï¸ ZFS POOLS STATUS                                                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                  â•‘
â•‘  â”Œâ”€ POOL: rpool â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
â•‘  â”‚ Status: ğŸŸ¢ ONLINE    Health: HEALTHY    Scrub: 2d ago (no errors)        â”‚  â•‘
â•‘  â”‚ Size: 447 GB         Used: 245 GB (55%)        Free: 202 GB              â”‚  â•‘
â•‘  â”‚                                                                           â”‚  â•‘
â•‘  â”‚ Configuration:                                                            â”‚  â•‘
â•‘  â”‚   rpool                                   ONLINE                          â”‚  â•‘
â•‘  â”‚     mirror-0                              ONLINE                          â”‚  â•‘
â•‘  â”‚       /dev/disk/by-id/nvme-Samsung_1      ONLINE                          â”‚  â•‘
â•‘  â”‚       /dev/disk/by-id/nvme-Samsung_2      ONLINE                          â”‚  â•‘
â•‘  â”‚                                                                           â”‚  â•‘
â•‘  â”‚ Properties: compression=lz4, atime=off, recordsize=128K                   â”‚  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
â•‘                                                                                  â•‘
â•‘  â”Œâ”€ POOL: tank â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
â•‘  â”‚ Status: ğŸŸ¢ ONLINE    Health: HEALTHY    Scrub: 5d ago (no errors)        â”‚  â•‘
â•‘  â”‚ Size: 10.9 TB        Used: 4.2 TB (38%)        Free: 6.7 TB              â”‚  â•‘
â•‘  â”‚                                                                           â”‚  â•‘
â•‘  â”‚ Configuration:                                                            â”‚  â•‘
â•‘  â”‚   tank                                    ONLINE                          â”‚  â•‘
â•‘  â”‚     raidz2-0                              ONLINE                          â”‚  â•‘
â•‘  â”‚       /dev/disk/by-id/scsi-ST4000_1       ONLINE                          â”‚  â•‘
â•‘  â”‚       /dev/disk/by-id/scsi-ST4000_2       ONLINE                          â”‚  â•‘
â•‘  â”‚       /dev/disk/by-id/scsi-ST4000_3       ONLINE                          â”‚  â•‘
â•‘  â”‚       /dev/disk/by-id/scsi-ST4000_4       ONLINE                          â”‚  â•‘
â•‘  â”‚       /dev/disk/by-id/scsi-ST4000_5       ONLINE                          â”‚  â•‘
â•‘  â”‚       /dev/disk/by-id/scsi-ST4000_6       ONLINE                          â”‚  â•‘
â•‘  â”‚     special                               ONLINE                          â”‚  â•‘
â•‘  â”‚       mirror-1                            ONLINE                          â”‚  â•‘
â•‘  â”‚         /dev/disk/by-id/nvme-Intel_1      ONLINE                          â”‚  â•‘
â•‘  â”‚         /dev/disk/by-id/nvme-Intel_2      ONLINE                          â”‚  â•‘
â•‘  â”‚                                                                           â”‚  â•‘
â•‘  â”‚ Properties: compression=lz4, atime=off, special_small_blocks=32K         â”‚  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
â•‘                                                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## Commandes Bash

### Status et Information

```bash
# Status tous pools
zpool status

# Status pool spÃ©cifique
zpool status tank

# Liste pools avec usage
zpool list

# Liste datasets
zfs list

# Liste datasets avec snapshots
zfs list -t all

# I/O stats
zpool iostat -v tank 5

# Historique commandes
zpool history tank
```

### CrÃ©ation de Pools - Best Practices 2025-2026

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CRÃ‰ATION POOL - BEST PRACTICES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Mirror (2 disques) - Petit setup, haute performance
zpool create -o ashift=12 \
  -O compression=lz4 \
  -O atime=off \
  -O xattr=sa \
  -O acltype=posixacl \
  tank mirror \
  /dev/disk/by-id/scsi-disk1 \
  /dev/disk/by-id/scsi-disk2

# RAIDZ1 (3+ disques) - Dev/Test seulement
zpool create -o ashift=12 \
  -O compression=lz4 \
  -O atime=off \
  tank raidz1 \
  /dev/disk/by-id/scsi-disk{1,2,3,4}

# RAIDZ2 (6+ disques) - Production recommandÃ©
zpool create -o ashift=12 \
  -O compression=lz4 \
  -O atime=off \
  -O xattr=sa \
  -O acltype=posixacl \
  tank raidz2 \
  /dev/disk/by-id/scsi-disk{1,2,3,4,5,6}

# RAIDZ3 (8+ disques) - Haute redondance
zpool create -o ashift=12 \
  -O compression=lz4 \
  -O atime=off \
  tank raidz3 \
  /dev/disk/by-id/scsi-disk{1,2,3,4,5,6,7,8}

# Pool avec Special VDEV (metadata sur SSD)
zpool create -o ashift=12 \
  -O compression=lz4 \
  -O atime=off \
  -O special_small_blocks=32K \
  tank raidz2 \
  /dev/disk/by-id/scsi-hdd{1,2,3,4,5,6} \
  special mirror \
  /dev/disk/by-id/nvme-ssd1 \
  /dev/disk/by-id/nvme-ssd2

# â•â• BEST PRACTICES ZFS 2025 â•â•
# - ashift=12: Toujours pour disques modernes (4K sectors)
# - compression=lz4: Quasi gratuit, toujours activer
# - atime=off: Performance I/O
# - RAIDZ2: Minimum pour production
# - Special vdev: AccÃ©lÃ¨re metadata (miroir obligatoire)
# - Utiliser by-id: Ã‰vite problÃ¨mes aprÃ¨s reboot
```

### RAIDZ Expansion (ZFS 2.3+ / PVE 9+)

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RAIDZ EXPANSION - NOUVEAUTÃ‰ ZFS 2.3 (PVE 9+)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# VÃ©rifier version ZFS
zfs version  # Doit Ãªtre 2.3.0+

# Ã‰tat actuel
zpool status tank
# tank  ONLINE
#   raidz2-0  ONLINE
#     disk1   ONLINE
#     disk2   ONLINE
#     disk3   ONLINE
#     disk4   ONLINE

# Ajouter disque au RAIDZ existant (expansion!)
zpool attach tank raidz2-0 /dev/disk/by-id/scsi-disk5

# VÃ©rifier progression
zpool status tank
# Expansion en cours... 45% complete

# IMPORTANT: L'expansion peut prendre des heures/jours
# Le pool reste accessible pendant l'opÃ©ration

# â•â• NOTES RAIDZ EXPANSION â•â•
# - Disponible ZFS 2.3.0+ (PVE 9+)
# - Un seul disque Ã  la fois
# - Pool reste online pendant expansion
# - Performance rÃ©duite pendant opÃ©ration
# - Planifier pendant pÃ©riode calme
```

### Gestion des Datasets

```bash
# CrÃ©er dataset
zfs create tank/vms
zfs create tank/containers
zfs create tank/backups

# CrÃ©er avec quota
zfs create -o quota=500G tank/vms

# CrÃ©er avec rÃ©servation
zfs create -o reservation=100G tank/critical

# PropriÃ©tÃ©s dataset
zfs get all tank/vms

# Modifier propriÃ©tÃ©s
zfs set compression=zstd tank/backups
zfs set recordsize=1M tank/backups  # Pour gros fichiers sÃ©quentiels
zfs set sync=disabled tank/scratch  # Si perte acceptable

# Renommer dataset
zfs rename tank/old tank/new

# Supprimer dataset
zfs destroy tank/test

# Supprimer avec descendants
zfs destroy -r tank/old
```

### Snapshots ZFS

```bash
# CrÃ©er snapshot
zfs snapshot tank/vms@daily-$(date +%Y%m%d)

# Snapshot rÃ©cursif
zfs snapshot -r tank@backup-pre-upgrade

# Lister snapshots
zfs list -t snapshot

# Lister snapshots d'un dataset
zfs list -t snapshot -r tank/vms

# Espace utilisÃ© par snapshots
zfs list -o name,used,refer -t snapshot

# Rollback (attention: perte donnÃ©es aprÃ¨s snapshot)
zfs rollback tank/vms@daily-20250201

# Rollback forcÃ© (dÃ©truit snapshots intermÃ©diaires)
zfs rollback -r tank/vms@daily-20250101

# Supprimer snapshot
zfs destroy tank/vms@old-snapshot

# Supprimer snapshots en batch
zfs destroy tank/vms@daily-202401%  # Pattern matching
```

### RÃ©plication ZFS

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RÃ‰PLICATION ZFS (entre nodes)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Envoi initial complet
zfs snapshot tank/vms@initial
zfs send tank/vms@initial | ssh pve02 zfs receive backup/vms

# Envoi incrÃ©mental
zfs snapshot tank/vms@snap2
zfs send -i tank/vms@initial tank/vms@snap2 | ssh pve02 zfs receive backup/vms

# Envoi compressÃ© (plus rapide sur rÃ©seau lent)
zfs send tank/vms@snap | gzip | ssh pve02 "gunzip | zfs receive backup/vms"

# Envoi avec pv pour progression
zfs send -v tank/vms@snap | pv | ssh pve02 zfs receive backup/vms

# RÃ©plication rÃ©cursive
zfs send -R tank@snap | ssh pve02 zfs receive -F backup

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RÃ‰PLICATION PROXMOX INTÃ‰GRÃ‰E (pour VMs)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# CrÃ©er job de rÃ©plication
pvesr create-local-job 100-0 pve02 --schedule '*/15' --rate 50

# Lister jobs
pvesr list

# Status rÃ©plication
pvesr status

# ExÃ©cuter rÃ©plication manuellement
pvesr run 100-0

# Supprimer job
pvesr delete 100-0
```

### Maintenance

```bash
# Scrub (vÃ©rification intÃ©gritÃ©) - Hebdomadaire recommandÃ©
zpool scrub tank

# Progression scrub
zpool status tank | grep -A5 scan

# Annuler scrub
zpool scrub -s tank

# Trim (SSD) - Automatique si supportÃ©
zpool trim tank

# Clear erreurs (aprÃ¨s remplacement disque)
zpool clear tank

# Importer pool (aprÃ¨s dÃ©placement)
zpool import
zpool import tank

# Exporter pool (avant dÃ©placement)
zpool export tank
```

### Remplacement de Disque

```bash
# Identifier disque dÃ©faillant
zpool status tank  # Chercher DEGRADED ou FAULTED

# Remplacer disque online (hot spare ou nouveau)
zpool replace tank /dev/disk/by-id/old-disk /dev/disk/by-id/new-disk

# Progression resilver
zpool status tank

# Si disque complÃ¨tement mort
zpool offline tank /dev/disk/by-id/dead-disk
# Installer nouveau disque physiquement
zpool replace tank /dev/disk/by-id/dead-disk /dev/disk/by-id/new-disk

# Retirer disque d'un mirror (rÃ©duction)
zpool detach tank /dev/disk/by-id/disk-to-remove
```

### Ajout Stockage Proxmox

```bash
# Ajouter pool ZFS comme storage Proxmox
pvesm add zfspool local-zfs \
  --pool tank/vms \
  --content images,rootdir \
  --sparse 1

# Avec thin provisioning
pvesm add zfspool tank-vms \
  --pool tank/proxmox \
  --content images,rootdir \
  --sparse 1 \
  --blocksize 8k
```

## Wizard : CrÃ©ation Pool ZFS

```
/pve-zfs create --wizard
```

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ§™ WIZARD: CRÃ‰ATION POOL ZFS                                                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  Ã‰tape 1/4: SÃ‰LECTION DISQUES                                                â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘  Disques disponibles:                                                        â•‘
â•‘    [1] /dev/sdb - ST4000NM 4TB (SMART: OK)                                   â•‘
â•‘    [2] /dev/sdc - ST4000NM 4TB (SMART: OK)                                   â•‘
â•‘    [3] /dev/sdd - ST4000NM 4TB (SMART: OK)                                   â•‘
â•‘    [4] /dev/sde - ST4000NM 4TB (SMART: OK)                                   â•‘
â•‘    [5] /dev/sdf - ST4000NM 4TB (SMART: OK)                                   â•‘
â•‘    [6] /dev/sdg - ST4000NM 4TB (SMART: OK)                                   â•‘
â•‘    [7] /dev/nvme0n1 - Samsung 980 1TB (SMART: OK)                            â•‘
â•‘    [8] /dev/nvme1n1 - Samsung 980 1TB (SMART: OK)                            â•‘
â•‘                                                                              â•‘
â•‘  SÃ©lection (ex: 1,2,3,4,5,6): > 1,2,3,4,5,6                                  â•‘
â•‘                                                                              â•‘
â•‘  Ã‰tape 2/4: NIVEAU RAID                                                      â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘  Avec 6 disques, options disponibles:                                        â•‘
â•‘    [1] RAIDZ2 (4+2)    â† RecommandÃ© production                               â•‘
â•‘        CapacitÃ©: ~16TB | TolÃ©rance: 2 disques                                â•‘
â•‘    [2] RAIDZ1 (5+1)                                                          â•‘
â•‘        CapacitÃ©: ~20TB | TolÃ©rance: 1 disque                                 â•‘
â•‘    [3] Mirror (3x2)                                                          â•‘
â•‘        CapacitÃ©: ~12TB | TolÃ©rance: 1 par groupe                             â•‘
â•‘    [4] RAIDZ3 (3+3)    â† Ultra-redondant                                     â•‘
â•‘        CapacitÃ©: ~12TB | TolÃ©rance: 3 disques                                â•‘
â•‘  Choix:              > 1                                                     â•‘
â•‘                                                                              â•‘
â•‘  Ã‰tape 3/4: SPECIAL VDEV (optionnel)                                         â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘  Ajouter Special VDEV pour accÃ©lÃ©rer metadata?                               â•‘
â•‘    [1] Non                                                                   â•‘
â•‘    [2] Oui - utiliser NVMe 7,8 en mirror                                     â•‘
â•‘  Choix:              > 2                                                     â•‘
â•‘                                                                              â•‘
â•‘  Ã‰tape 4/4: OPTIONS                                                          â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘  Nom du pool:        > tank                                                  â•‘
â•‘  Compression:                                                                â•‘
â•‘    [1] lz4            â† RecommandÃ© (rapide)                                  â•‘
â•‘    [2] zstd           â† Meilleur ratio                                       â•‘
â•‘    [3] off                                                                   â•‘
â•‘  Choix:              > 1                                                     â•‘
â•‘                                                                              â•‘
â•‘  atime:              [y/N] > N                                               â•‘
â•‘  Ajouter Ã  Proxmox:  [Y/n] > Y                                               â•‘
â•‘                                                                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ğŸ“‹ RÃ‰SUMÃ‰                                                                   â•‘
â•‘  Pool: tank    Type: RAIDZ2    Disques: 6x 4TB + 2x 1TB NVMe special        â•‘
â•‘  CapacitÃ© utile: ~16 TB    Options: compression=lz4, atime=off              â•‘
â•‘                                                                              â•‘
â•‘  Commande:                                                                   â•‘
â•‘  zpool create -o ashift=12 -O compression=lz4 -O atime=off \                 â•‘
â•‘    -O special_small_blocks=32K tank raidz2 \                                 â•‘
â•‘    /dev/disk/by-id/scsi-{1,2,3,4,5,6} \                                      â•‘
â•‘    special mirror /dev/disk/by-id/nvme-{1,2}                                 â•‘
â•‘                                                                              â•‘
â•‘  Confirmer? [Y/n] > Y                                                        â•‘
â•‘                                                                              â•‘
â•‘  âœ… Pool tank crÃ©Ã© avec succÃ¨s!                                              â•‘
â•‘  âœ… Storage local-zfs ajoutÃ© Ã  Proxmox                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## Voir Aussi
- `/pve-storage` - Gestion stockage gÃ©nÃ©ral
- `/pve-ceph` - Administration Ceph
- `/pve-backup` - Backup et rÃ©plication
